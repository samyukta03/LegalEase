{"ast":null,"code":"import _slicedToArray from\"F:/Project-Legal.ly/node_modules/@babel/runtime/helpers/esm/slicedToArray.js\";import React,{useState}from\"react\";import SpeechRecognition,{useSpeechRecognition}from\"react-speech-recognition\";import Mic from\"../Assets/mic.svg\";import OnMic from\"../Assets/micon.svg\";import{jsx as _jsx}from\"react/jsx-runtime\";var Dictaphone=function Dictaphone(_ref){var input=_ref.input,setinput=_ref.setinput;var _useState=useState(false),_useState2=_slicedToArray(_useState,2),mic=_useState2[0],setMic=_useState2[1];var lang=\"en-US\";// Initialize lang as English\nvar _useSpeechRecognition=useSpeechRecognition(),transcript=_useSpeechRecognition.transcript,listening=_useSpeechRecognition.listening,resetTranscript=_useSpeechRecognition.resetTranscript,browserSupportsSpeechRecognition=_useSpeechRecognition.browserSupportsSpeechRecognition;if(!browserSupportsSpeechRecognition){return alert(\"Browser doesn't support speech recognition\");}var onMicStart=function onMicStart(){setMic(!mic);if(mic){SpeechRecognition.startListening({language:lang// Use the current value of lang\n});}else{SpeechRecognition.stopListening();}};var handleTranscript=function handleTranscript(newTranscript){console.log(\"Detected language:\",lang);// Log the detected language\nsetinput(newTranscript);if(newTranscript.toLowerCase()===\"tamil\"){lang=\"ta-IN\";// Change language to Tamil\n}else{lang=\"en-US\";// Change language back to English\n}};// Set up the recognition\nSpeechRecognition.onResult(handleTranscript);return/*#__PURE__*/_jsx(\"div\",{children:/*#__PURE__*/_jsx(\"img\",{src:listening?OnMic:Mic,alt:\"Mic\",className:\"w-[4.5vw] h-[5vh] mt-2 px-0 cursor-pointer transition-all user-select-none\",onClick:onMicStart})});};export default Dictaphone;// import React, { useState } from \"react\";\n// import SpeechRecognition, {\n//   useSpeechRecognition,\n// } from \"react-speech-recognition\";\n// import Mic from \"../Assets/mic.svg\";\n// import OnMic from \"../Assets/micon.svg\";\n// const Dictaphone = ({ input, setinput }) => {\n//   const [mic, setMic] = useState(false);\n//   const {\n//     transcript,\n//     listening,\n//     resetTranscript,\n//     browserSupportsSpeechRecognition,\n//   } = useSpeechRecognition();\n//   if (!browserSupportsSpeechRecognition) {\n//     return alert(\"Browser doesn't support speech recognition\");\n//   }\n//   const onMicStart = () => {\n//     setMic(!mic);\n//     mic\n//       ? SpeechRecognition.startListening()\n//       : SpeechRecognition.stopListening();\n//     console.log(transcript);\n//     setinput(transcript);\n//   };\n//   return (\n//     <div>\n//       <img\n//         src={listening ? OnMic : Mic}\n//         alt=\"Mic\"\n//         className=\"w-[4.5vw] h-[5vh] mt-2 px-0 cursor-pointer transition-all user-select-none\"\n//         onClick={onMicStart}\n//       />\n//     </div>\n//   );\n// };\n// export default Dictaphone;","map":{"version":3,"sources":["F:/Project-Legal.ly/src/Components/Dictaphone.js"],"names":["React","useState","SpeechRecognition","useSpeechRecognition","Mic","OnMic","Dictaphone","input","setinput","mic","setMic","lang","transcript","listening","resetTranscript","browserSupportsSpeechRecognition","alert","onMicStart","startListening","language","stopListening","handleTranscript","newTranscript","console","log","toLowerCase","onResult"],"mappings":"yGAAA,MAAOA,CAAAA,KAAP,EAAgBC,QAAhB,KAAgC,OAAhC,CACA,MAAOC,CAAAA,iBAAP,EACEC,oBADF,KAEO,0BAFP,CAGA,MAAOC,CAAAA,GAAP,KAAgB,mBAAhB,CACA,MAAOC,CAAAA,KAAP,KAAkB,qBAAlB,C,2CAEA,GAAMC,CAAAA,UAAU,CAAG,QAAbA,CAAAA,UAAa,MAAyB,IAAtBC,CAAAA,KAAsB,MAAtBA,KAAsB,CAAfC,QAAe,MAAfA,QAAe,CAC1C,cAAsBP,QAAQ,CAAC,KAAD,CAA9B,wCAAOQ,GAAP,eAAYC,MAAZ,eACA,GAAIC,CAAAA,IAAI,CAAG,OAAX,CAAoB;AAEpB,0BAKIR,oBAAoB,EALxB,CACES,UADF,uBACEA,UADF,CAEEC,SAFF,uBAEEA,SAFF,CAGEC,eAHF,uBAGEA,eAHF,CAIEC,gCAJF,uBAIEA,gCAJF,CAOA,GAAI,CAACA,gCAAL,CAAuC,CACrC,MAAOC,CAAAA,KAAK,CAAC,4CAAD,CAAZ,CACD,CAED,GAAMC,CAAAA,UAAU,CAAG,QAAbA,CAAAA,UAAa,EAAM,CACvBP,MAAM,CAAC,CAACD,GAAF,CAAN,CACA,GAAIA,GAAJ,CAAS,CACPP,iBAAiB,CAACgB,cAAlB,CAAiC,CAC/BC,QAAQ,CAAER,IAAM;AADe,CAAjC,EAGD,CAJD,IAIO,CACLT,iBAAiB,CAACkB,aAAlB,GACD,CACF,CATD,CAWA,GAAMC,CAAAA,gBAAgB,CAAG,QAAnBA,CAAAA,gBAAmB,CAACC,aAAD,CAAmB,CAC1CC,OAAO,CAACC,GAAR,CAAY,oBAAZ,CAAkCb,IAAlC,EAAyC;AACzCH,QAAQ,CAACc,aAAD,CAAR,CACA,GAAIA,aAAa,CAACG,WAAd,KAAgC,OAApC,CAA6C,CAC3Cd,IAAI,CAAG,OAAP,CAAgB;AACjB,CAFD,IAEO,CACLA,IAAI,CAAG,OAAP,CAAgB;AACjB,CACF,CARD,CAUA;AACAT,iBAAiB,CAACwB,QAAlB,CAA2BL,gBAA3B,EAEA,mBACE,kCACE,YACE,GAAG,CAAER,SAAS,CAAGR,KAAH,CAAWD,GAD3B,CAEE,GAAG,CAAC,KAFN,CAGE,SAAS,CAAC,4EAHZ,CAIE,OAAO,CAAEa,UAJX,EADF,EADF,CAUD,CAjDD,CAmDA,cAAeX,CAAAA,UAAf,CACA;AAEA;AACA;AACA;AACA;AACA;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA","sourcesContent":["import React, { useState } from \"react\";\r\nimport SpeechRecognition, {\r\n  useSpeechRecognition,\r\n} from \"react-speech-recognition\";\r\nimport Mic from \"../Assets/mic.svg\";\r\nimport OnMic from \"../Assets/micon.svg\";\r\n\r\nconst Dictaphone = ({ input, setinput }) => {\r\n  const [mic, setMic] = useState(false);\r\n  let lang = \"en-US\"; // Initialize lang as English\r\n\r\n  const {\r\n    transcript,\r\n    listening,\r\n    resetTranscript,\r\n    browserSupportsSpeechRecognition,\r\n  } = useSpeechRecognition();\r\n\r\n  if (!browserSupportsSpeechRecognition) {\r\n    return alert(\"Browser doesn't support speech recognition\");\r\n  }\r\n\r\n  const onMicStart = () => {\r\n    setMic(!mic);\r\n    if (mic) {\r\n      SpeechRecognition.startListening({\r\n        language: lang, // Use the current value of lang\r\n      });\r\n    } else {\r\n      SpeechRecognition.stopListening();\r\n    }\r\n  };\r\n\r\n  const handleTranscript = (newTranscript) => {\r\n    console.log(\"Detected language:\", lang); // Log the detected language\r\n    setinput(newTranscript);\r\n    if (newTranscript.toLowerCase() === \"tamil\") {\r\n      lang = \"ta-IN\"; // Change language to Tamil\r\n    } else {\r\n      lang = \"en-US\"; // Change language back to English\r\n    }\r\n  };\r\n\r\n  // Set up the recognition\r\n  SpeechRecognition.onResult(handleTranscript);\r\n\r\n  return (\r\n    <div>\r\n      <img\r\n        src={listening ? OnMic : Mic}\r\n        alt=\"Mic\"\r\n        className=\"w-[4.5vw] h-[5vh] mt-2 px-0 cursor-pointer transition-all user-select-none\"\r\n        onClick={onMicStart}\r\n      />\r\n    </div>\r\n  );\r\n};\r\n\r\nexport default Dictaphone;\r\n// import React, { useState } from \"react\";\r\n\r\n// import SpeechRecognition, {\r\n//   useSpeechRecognition,\r\n// } from \"react-speech-recognition\";\r\n// import Mic from \"../Assets/mic.svg\";\r\n// import OnMic from \"../Assets/micon.svg\";\r\n\r\n// const Dictaphone = ({ input, setinput }) => {\r\n//   const [mic, setMic] = useState(false);\r\n//   const {\r\n//     transcript,\r\n//     listening,\r\n//     resetTranscript,\r\n//     browserSupportsSpeechRecognition,\r\n//   } = useSpeechRecognition();\r\n\r\n//   if (!browserSupportsSpeechRecognition) {\r\n//     return alert(\"Browser doesn't support speech recognition\");\r\n//   }\r\n//   const onMicStart = () => {\r\n//     setMic(!mic);\r\n//     mic\r\n//       ? SpeechRecognition.startListening()\r\n//       : SpeechRecognition.stopListening();\r\n//     console.log(transcript);\r\n//     setinput(transcript);\r\n//   };\r\n\r\n//   return (\r\n//     <div>\r\n//       <img\r\n//         src={listening ? OnMic : Mic}\r\n//         alt=\"Mic\"\r\n//         className=\"w-[4.5vw] h-[5vh] mt-2 px-0 cursor-pointer transition-all user-select-none\"\r\n//         onClick={onMicStart}\r\n//       />\r\n//     </div>\r\n//   );\r\n// };\r\n// export default Dictaphone;\r\n"]},"metadata":{},"sourceType":"module"}