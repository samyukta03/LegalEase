{"ast":null,"code":"import _slicedToArray from\"F:/Project-Legal.ly/node_modules/@babel/runtime/helpers/esm/slicedToArray.js\";import React,{useState}from\"react\";import SpeechRecognition,{useSpeechRecognition}from\"react-speech-recognition\";import Mic from\"../Assets/mic.svg\";import OnMic from\"../Assets/micon.svg\";import{jsx as _jsx}from\"react/jsx-runtime\";var Dictaphone=function Dictaphone(_ref){var input=_ref.input,setinput=_ref.setinput;var _useState=useState(false),_useState2=_slicedToArray(_useState,2),mic=_useState2[0],setMic=_useState2[1];var _useSpeechRecognition=useSpeechRecognition(),transcript=_useSpeechRecognition.transcript,listening=_useSpeechRecognition.listening,resetTranscript=_useSpeechRecognition.resetTranscript,browserSupportsSpeechRecognition=_useSpeechRecognition.browserSupportsSpeechRecognition;if(!browserSupportsSpeechRecognition){return alert(\"Browser doesn't support speech recognition\");}var onMicStart=function onMicStart(){setMic(!mic);if(mic){SpeechRecognition.startListening({language:\"en-IN,ta-IN\"// Specify English and Tamil languages\n});}else{SpeechRecognition.stopListening();}console.log(transcript);setinput(transcript);};return/*#__PURE__*/_jsx(\"div\",{children:/*#__PURE__*/_jsx(\"img\",{src:listening?OnMic:Mic,alt:\"Mic\",className:\"w-[4.5vw] h-[5vh] mt-2 px-0 cursor-pointer transition-all user-select-none\",onClick:onMicStart})});};export default Dictaphone;// import React, { useState } from \"react\";\n// import SpeechRecognition, {\n//   useSpeechRecognition,\n// } from \"react-speech-recognition\";\n// import Mic from \"../Assets/mic.svg\";\n// import OnMic from \"../Assets/micon.svg\";\n// const Dictaphone = ({ input, setinput }) => {\n//   const [mic, setMic] = useState(false);\n//   const {\n//     transcript,\n//     listening,\n//     resetTranscript,\n//     browserSupportsSpeechRecognition,\n//   } = useSpeechRecognition();\n//   if (!browserSupportsSpeechRecognition) {\n//     return alert(\"Browser doesn't support speech recognition\");\n//   }\n//   const onMicStart = () => {\n//     setMic(!mic);\n//     mic\n//       ? SpeechRecognition.startListening()\n//       : SpeechRecognition.stopListening();\n//     console.log(transcript);\n//     setinput(transcript);\n//   };\n//   return (\n//     <div>\n//       <img\n//         src={listening ? OnMic : Mic}\n//         alt=\"Mic\"\n//         className=\"w-[4.5vw] h-[5vh] mt-2 px-0 cursor-pointer transition-all user-select-none\"\n//         onClick={onMicStart}\n//       />\n//     </div>\n//   );\n// };\n// export default Dictaphone;","map":{"version":3,"sources":["F:/Project-Legal.ly/src/Components/Dictaphone.js"],"names":["React","useState","SpeechRecognition","useSpeechRecognition","Mic","OnMic","Dictaphone","input","setinput","mic","setMic","transcript","listening","resetTranscript","browserSupportsSpeechRecognition","alert","onMicStart","startListening","language","stopListening","console","log"],"mappings":"yGAAA,MAAOA,CAAAA,KAAP,EAAgBC,QAAhB,KAAgC,OAAhC,CACA,MAAOC,CAAAA,iBAAP,EAA4BC,oBAA5B,KAAwD,0BAAxD,CACA,MAAOC,CAAAA,GAAP,KAAgB,mBAAhB,CACA,MAAOC,CAAAA,KAAP,KAAkB,qBAAlB,C,2CAEA,GAAMC,CAAAA,UAAU,CAAG,QAAbA,CAAAA,UAAa,MAAyB,IAAtBC,CAAAA,KAAsB,MAAtBA,KAAsB,CAAfC,QAAe,MAAfA,QAAe,CAC1C,cAAsBP,QAAQ,CAAC,KAAD,CAA9B,wCAAOQ,GAAP,eAAYC,MAAZ,eACA,0BAKIP,oBAAoB,EALxB,CACEQ,UADF,uBACEA,UADF,CAEEC,SAFF,uBAEEA,SAFF,CAGEC,eAHF,uBAGEA,eAHF,CAIEC,gCAJF,uBAIEA,gCAJF,CAOA,GAAI,CAACA,gCAAL,CAAuC,CACrC,MAAOC,CAAAA,KAAK,CAAC,4CAAD,CAAZ,CACD,CAED,GAAMC,CAAAA,UAAU,CAAG,QAAbA,CAAAA,UAAa,EAAM,CACvBN,MAAM,CAAC,CAACD,GAAF,CAAN,CACA,GAAIA,GAAJ,CAAS,CACPP,iBAAiB,CAACe,cAAlB,CAAiC,CAC/BC,QAAQ,CAAE,aAAc;AADO,CAAjC,EAGD,CAJD,IAIO,CACLhB,iBAAiB,CAACiB,aAAlB,GACD,CACDC,OAAO,CAACC,GAAR,CAAYV,UAAZ,EACAH,QAAQ,CAACG,UAAD,CAAR,CACD,CAXD,CAaA,mBACE,kCACE,YACE,GAAG,CAAEC,SAAS,CAAGP,KAAH,CAAWD,GAD3B,CAEE,GAAG,CAAC,KAFN,CAGE,SAAS,CAAC,4EAHZ,CAIE,OAAO,CAAEY,UAJX,EADF,EADF,CAUD,CApCD,CAsCA,cAAeV,CAAAA,UAAf,CACA;AAEA;AACA;AACA;AACA;AACA;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA","sourcesContent":["import React, { useState } from \"react\";\r\nimport SpeechRecognition, { useSpeechRecognition } from \"react-speech-recognition\";\r\nimport Mic from \"../Assets/mic.svg\";\r\nimport OnMic from \"../Assets/micon.svg\";\r\n\r\nconst Dictaphone = ({ input, setinput }) => {\r\n  const [mic, setMic] = useState(false);\r\n  const {\r\n    transcript,\r\n    listening,\r\n    resetTranscript,\r\n    browserSupportsSpeechRecognition,\r\n  } = useSpeechRecognition();\r\n\r\n  if (!browserSupportsSpeechRecognition) {\r\n    return alert(\"Browser doesn't support speech recognition\");\r\n  }\r\n\r\n  const onMicStart = () => {\r\n    setMic(!mic);\r\n    if (mic) {\r\n      SpeechRecognition.startListening({\r\n        language: \"en-IN,ta-IN\" // Specify English and Tamil languages\r\n      });\r\n    } else {\r\n      SpeechRecognition.stopListening();\r\n    }\r\n    console.log(transcript);\r\n    setinput(transcript);\r\n  };\r\n\r\n  return (\r\n    <div>\r\n      <img\r\n        src={listening ? OnMic : Mic}\r\n        alt=\"Mic\"\r\n        className=\"w-[4.5vw] h-[5vh] mt-2 px-0 cursor-pointer transition-all user-select-none\"\r\n        onClick={onMicStart}\r\n      />\r\n    </div>\r\n  );\r\n};\r\n\r\nexport default Dictaphone;\r\n// import React, { useState } from \"react\";\r\n\r\n// import SpeechRecognition, {\r\n//   useSpeechRecognition,\r\n// } from \"react-speech-recognition\";\r\n// import Mic from \"../Assets/mic.svg\";\r\n// import OnMic from \"../Assets/micon.svg\";\r\n\r\n// const Dictaphone = ({ input, setinput }) => {\r\n//   const [mic, setMic] = useState(false);\r\n//   const {\r\n//     transcript,\r\n//     listening,\r\n//     resetTranscript,\r\n//     browserSupportsSpeechRecognition,\r\n//   } = useSpeechRecognition();\r\n\r\n//   if (!browserSupportsSpeechRecognition) {\r\n//     return alert(\"Browser doesn't support speech recognition\");\r\n//   }\r\n//   const onMicStart = () => {\r\n//     setMic(!mic);\r\n//     mic\r\n//       ? SpeechRecognition.startListening()\r\n//       : SpeechRecognition.stopListening();\r\n//     console.log(transcript);\r\n//     setinput(transcript);\r\n//   };\r\n\r\n//   return (\r\n//     <div>\r\n//       <img\r\n//         src={listening ? OnMic : Mic}\r\n//         alt=\"Mic\"\r\n//         className=\"w-[4.5vw] h-[5vh] mt-2 px-0 cursor-pointer transition-all user-select-none\"\r\n//         onClick={onMicStart}\r\n//       />\r\n//     </div>\r\n//   );\r\n// };\r\n// export default Dictaphone;\r\n"]},"metadata":{},"sourceType":"module"}